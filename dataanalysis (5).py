# -*- coding: utf-8 -*-
"""dataAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18TsY3jTEmGnYVwBIw9e4OM6Mp5nVhYAN
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score

# Load the CSV file
df = pd.read_csv('DIWALI.csv', encoding='unicode_escape')

# Display initial information about the dataframe
print("Initial shape:", df.shape)
print(df.head())
print(df.info())

# Drop unrelated/blank columns
df.drop(['User_ID', 'Cust_name', 'Zone'], axis=1, inplace=True)
#print("After dropping columns:", df.shape)

# Drop rows with null values
df.dropna(inplace=True)
#print("After dropping NA:", df.shape)

# Change data type of 'Amount' and 'Orders' columns
df['Amount'] = df['Amount'].astype(int)
df['Orders'] = df['Orders'].astype(int)

# Display intermediate results
print("After data type conversion:", df.shape)
print(df.head())

# Encode categorical variables using pd.get_dummies
df_encoded = pd.get_dummies(df, columns=['Gender', 'Age Group', 'Marital_Status', 'State', 'Occupation', 'Product_Category'],
                            prefix=['Gender', 'Age_Group', 'Marital_Status', 'State', 'Occupation', 'Product_Category'],
                            drop_first=True)

print(df_encoded.head)

# Display basic information about the dataframe
print(df_encoded.shape)
print(df_encoded.info())
#df = df_encoded

# Display descriptive statistics
print(df.describe())
print(df[['Age', 'Orders', 'Amount']].describe())

print(df.columns)
print(df.describe())

# Gender distribution
plt.figure(figsize=(8, 5))
ax = sns.countplot(x='Gender', data=df)
plt.title('Gender Distribution')
plt.show()

# Gender vs Total Amount
sales_gen = df.groupby('Gender')['Amount'].sum().reset_index().sort_values(by='Amount', ascending=False)
plt.figure(figsize=(8, 5))
sns.barplot(x='Gender', y='Amount', data=sales_gen)
plt.title('Total Amount by Gender')
plt.show()

# Age Group distribution
plt.figure(figsize=(10, 5))
ax = sns.countplot(data = df, x = 'Age Group', hue = 'Gender')

for bars in ax.containers:
    ax.bar_label(bars)

plt.title('Age Group Distribution')
plt.show()

# Total Amount by Age Group
#sales_age = df.groupby('Age Group')['Amount'].sum().reset_index().sort_values(by='Amount', ascending=False)
plt.figure(figsize=(10, 5))
#sns.barplot(x='Age Group', y='Amount', data=sales_age)

sales_age = df.groupby(['Age Group'], as_index=False)['Amount'].sum().sort_values(by='Amount', ascending=False)

sns.barplot(x = 'Age Group',y= 'Amount' ,data = sales_age)

plt.title('Total Amount by Age Group')
plt.show()


# Total Amount vs Age Group

sales_state = df.groupby(['Product_Category'], as_index=False)['Amount'].sum().sort_values(by='Amount', ascending=False).head(10)

plt.title("Top Purchased Product Category")

sns.set(rc={'figure.figsize':(20,5)})
sns.barplot(data = sales_state, x = 'Product_Category',y= 'Amount')

# top 10 most sold products (something as above)

plt.title("Top 10 Most Sold Products")

df.groupby('Product_ID')['Orders'].sum().nlargest(10).sort_values(ascending=False).plot(kind='bar')

df1 = df_encoded

# Define the target variable and features
X = df1.drop('Amount', axis=1)
y = df1['Amount']

# Binning the 'Amount' into categories for classification (e.g., low, medium, high)
y = pd.cut(y, bins=[0, 5000, 15000, df['Amount'].max()], labels=[0, 1, 2])

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verify that there are no non-numeric columns left
print("Non-numeric columns in X_train:", X_train.select_dtypes(exclude=['float', 'int']).columns)

# Drop non-numeric columns (if any) before standardization
non_numeric_cols = X.select_dtypes(exclude=['float', 'int']).columns
X_train = X_train.drop(non_numeric_cols, axis=1)
X_test = X_test.drop(non_numeric_cols, axis=1)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train a Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=10, random_state=42)
rf_model.fit(X_train, y_train)

# Predict with Random Forest model
rf_y_pred = rf_model.predict(X_test)

# Evaluate the Random Forest model
rf_mse = mean_squared_error(y_test, rf_y_pred)
rf_r2 = r2_score(y_test, rf_y_pred)
rf_accuracy = accuracy_score(y_test, rf_y_pred)


print("Random Forest Model:")
print(f'Mean Squared Error: {rf_mse}')
print(f'R-squared: {rf_r2}')
print('Accuracy Score: {:.2f}%'.format(rf_accuracy * 100))

print("F1 Score:", f1_score(y_test, rf_y_pred, average='weighted'))

# Plot Random Forest predictions
plt.figure(figsize=(10, 5))
plt.scatter(y_test, rf_y_pred, alpha=0.3)
plt.plot([0, 2], [0, 2], '--r')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Random Forest Predictions')
plt.show()

# Train the AdaBoost model
ada_model = AdaBoostClassifier(random_state=42)
ada_model.fit(X_train_scaled, y_train)

# Predict with AdaBoost model
ada_y_pred = ada_model.predict(X_test_scaled)

# Evaluate the AdaBoost model
ada_mse = mean_squared_error(y_test, ada_y_pred)
ada_r2 = r2_score(y_test, ada_y_pred)
ada_accuracy = accuracy_score(y_test, ada_y_pred)

print("\nAdaBoost Model:")
print(f'Mean Squared Error: {ada_mse}')
print(f'R-squared: {ada_r2}')
print('Accuracy Score: {:.2f}%'.format(ada_accuracy * 100))
print("F1 Score:", f1_score(y_test, ada_y_pred, average='weighted'))

# Plot AdaBoost predictions
plt.figure(figsize=(10, 5))
plt.scatter(y_test, ada_y_pred, alpha=0.3)
plt.plot([0, 2], [0, 2], '--r')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('AdaBoost Predictions')
plt.show()

# Comparison of Random Forest and AdaBoost predictions
comparison_df = pd.DataFrame({
    'Actual': y_test,
    'RandomForest_Predicted': rf_y_pred,
    'AdaBoost_Predicted': ada_y_pred
})

plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.scatter(comparison_df['Actual'], comparison_df['RandomForest_Predicted'], alpha=0.3)
plt.plot([0, 2], [0, 2], '--r')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Random Forest Predictions')

plt.subplot(1, 2, 2)
plt.scatter(comparison_df['Actual'], comparison_df['AdaBoost_Predicted'], alpha=0.3)
plt.plot([0, 2], [0, 2], '--r')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('AdaBoost Predictions')

plt.show()

# Summary of the analysis
summary = {
    'Total Sales': df['Amount'].sum(),
    'Total Orders': df['Orders'].sum(),
    'Gender Distribution': df['Gender'].value_counts().to_dict(),
    'Top Purchasing Gender': df.groupby('Gender')['Amount'].sum().idxmax(),
    'Top Purchasing Age Group': df.groupby('Age Group')['Amount'].sum().idxmax(),
    'Top Purchasing State': df.groupby('State')['Amount'].sum().idxmax(),
    'Top Purchasing Product Category': df.groupby('Product_Category')['Amount'].sum().idxmax(),
    'Random Forest Model Performance': {
        'Mean Squared Error': mean_squared_error(y_test, rf_y_pred),
        'R2 Score': r2_score(y_test, rf_y_pred),
        'Accuracy Score': accuracy_score(y_test, rf_y_pred),
        'F1 Score': f1_score(y_test, rf_y_pred, average='weighted')
    }, 'Adaboost Model Performance': {
        'Mean Squared Error': mean_squared_error(y_test, ada_y_pred),
        'R2 Score': r2_score(y_test, ada_y_pred),
        'Accuracy Score': accuracy_score(y_test, ada_y_pred),
        'F1 Score': f1_score(y_test, ada_y_pred, average='weighted')
    }
}

for key, value in summary.items():
    print(f"{key}: {value}")

# Summary of Predictions
summary_df = pd.DataFrame({
    'Actual': y_test,
    'RandomForest_Predicted': rf_y_pred,
    'AdaBoost_Predicted': ada_y_pred
})
print("\nSummary of Predictions:")
print(summary_df.head())